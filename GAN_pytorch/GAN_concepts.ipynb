{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d130ab54",
   "metadata": {},
   "source": [
    "# Build Basic Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fd728a",
   "metadata": {},
   "source": [
    "## Generative Models\n",
    "\n",
    "* Variational Autoencoders (VAE)\n",
    "\n",
    "Training: img -> Encoder -> Latent Space -> Decoder -> img' (reconstruct image)\n",
    "\n",
    "Generating: random latent space -> Decoder -> generated img\n",
    "\n",
    "* Generative Adversarial Networks (GAN)\n",
    "\n",
    "Training:\n",
    "\n",
    "random noise -> **Generator** -> generated img\n",
    "\n",
    "generated img -> **Discriminator** -> real/fake img\n",
    "\n",
    "Generating:\n",
    "\n",
    "random noise -> Generator -> generated img\n",
    "\n",
    "\n",
    "## Binary Cross Entropy (BCE) Loss\n",
    "\n",
    "Deisgned for classification real/fake\n",
    "\n",
    "<img src=\"./images/BCE.png\" width=\"600\"/>\n",
    "\n",
    "- m: batch size\n",
    "- h: prediction made by model\n",
    "- y: true label\n",
    "- x: features (img)\n",
    "- $\\theta$: discriminator parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef05f4f",
   "metadata": {},
   "source": [
    "when prediction is 0 -> left part = 0<br>\n",
    "when prediction is 1 -> left part tells if h = 0, loss = inf; if h = 1, loss = 0\n",
    "\n",
    "when prediction is 1 -> right part = 0<br>\n",
    "when prediction is 0 -> right part tells if h = 0, loss = 0; if h = 1, loss = inf\n",
    "\n",
    "J -> 0 when label and prediction are close<br>\n",
    "J -> inf when label and prediction are different\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca5550",
   "metadata": {},
   "source": [
    "## Procedures\n",
    "\n",
    "Discriminator Training:\n",
    "\n",
    "<img src=\"./images/gan_train.png\" width=\"600\"/>\n",
    "\n",
    "Generator Training: (G wants to fool D as much as possible)\n",
    "\n",
    "<img src=\"./images/gan_train2.png\" width=\"600\"/>\n",
    "\n",
    "Both models should improve together and always be at a similar \"skill\" level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb2dc7",
   "metadata": {},
   "source": [
    "## Noise vector $z$\n",
    "\n",
    "The noise vector $z$ has the important role of making sure the images generated from the same class $y$ don't all look the same—think of it as a random seed. You generate it randomly, usually by sampling random numbers either between 0 and 1 uniformly, or from the normal distribution, which you can denote $z$ ~ $N(0, 1)$. The zero means the normal distribution has a mean of zero, and the 1 means that the normal distribution has a variance of 1. \n",
    "\n",
    "In reality, $z$ is usually larger than just 1 value to allow for more combinations of what $z$ could be. There's no special number that determines what works, but 100 is standard. Some researchers might use a power of 2, like 128 or 512, but again, nothing special about the number itself, just that it's large enough to contain a lot of possibilities. As a result, you would sample $z$ from that many different dimensions (constituting multiple normal distributions).\n",
    "\n",
    "*Fun Fact: this is also called a spherical normal and denoted $z$ ~ $N(0, I)$ where the $I$ represents the identity matrix and means the variance is 1 in all dimensions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b68e54",
   "metadata": {},
   "source": [
    "## Truncation trick\n",
    "\n",
    "So now that you're a bit familiar with noise vectors, here's another cool concept that people use to tune their outputs. It's called the truncation trick. I like to think of the truncation trick as a way of trading off fidelity (quality) and diversity in the samples. It works like this: when you randomly sample your noise vector $z$, you can choose to keep that random $z$ or you can sample another one. \n",
    "\n",
    "Why would you want to sample another one? \n",
    "\n",
    "Well, since I'm sampling $z$ from a normal distribution, my model will see more of those $z$ values within a standard deviation from the mean than those at the tails of the distribution—and this happens during training. This means that while the model is training, it's likely to be familiar with certain noise vectors and as a result model those areas coming from familiar noise vector regions. In these areas, my model will likely have much more realistic results, but nothing too funky, it's not taking as many risks in those regions mapped from those familiar noise vectors. This is the trade-off between fidelity (realistic, high quality images) and diversity (variety in images). \n",
    "\n",
    "What the truncation trick does is resamples the noise vector $z$ until it falls within some bounds of the normal distribution. In fact, it samples $z$ from a truncated normal distribution where the tails are cut off at different values (red line in graph is truncated normal, blue is original). You can tune these values and thus tune fidelity/diversity. Recall that having a lot of fidelity is not always the goal—one failure mode of that is that you get one really real image but nothing else (no diversity), and that's not very interesting or successful from a model that's supposed to model the realm of all possible human faces or that of all possible coconuts—including that of a cat pouncing after a flying coconut (but with extremely low probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912475c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
